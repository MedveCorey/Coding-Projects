## Compression Algorithm Compariosn
All four algortihms compress the files to some degree with the Unix algorithm having the best overall compression ratio for the files with many of them being compressed with a 2:1 ratio or even better in addition to not causing any file that was passed in to be compressed being bigger than the original size of the file. The second best overall compression algorithm I believe is the modified algorithm with the codebook resets with as many of the files end of being approximately 1.5 times or more smaller than the original file. Unlike the Unix compression algorithm the modified algorithms and the original implementation all cause expansion of files, I believe this is because that the Unix algorithm may have some sort of check to see if the compressed file would be bigger than the original file and if it is than it either stops compressing and returns the original file or that after it compresses the file it compares and returns whichever is smaller. The third best overall compression algorithm is the modified algorithm without the codebook resets, this one is very similar to the one with resets as they have the same compression ratio for some of the files, such as `assig2.doc` (17:8) or `code.txt` (71:24), or are very close in size (with some files being different by 1 kilobyte). It's safe to say these two are very much similar as they both have the same minimum and maximum codeword length it would cause smaller files that don't completely fill the codebook to have the same the size these two algorithms only then differ when you get to bigger files that will cause the codebook to reset as the file being compressed with resets will be able to continue to create new nine through sixteen bit codewords which allows for the file to be smaller compared to the one without resets since this one will have to use codewords that already exsist in the code book to finish compressing the file which is most likely not the most efficient for the remainder of the file. the worst algorithm of the four is the original implementation of the code with a majority of the files being 1.2 times smaller than the original. The original implementation is very different as (assuming the Unix algoritm uses adaptive codeword length) it is the only algorithm that has a fixed codeword length in addition to that it also does not reset the codebook when it becomes full which leads it to having a very limited number of codewords and as with the modified algorithm without resetting causes it to use whatever codewords are already in its codebook to encode the remainder of the file after the codebook is filled.

While all the algorithms compressed files differently/by different amounts the one thing that was similar for all of them were the files that were compressed worst/best with all the algoritms compressing `wacky.bmp` the best and the worst compressed files being either `frosty.jpg` or `Lego-big.gif`. `wacky.bmp` is by far the file that was compressed the best, as shown in the tables below `wacky.bmp` was originally 901KB and after compression the size of the file is 4KB for all the algorithms, except for the original implementation which was 5KB, which results in a ratio of 901:4 which means the compressed file is 225.25 times smaller than the original file. I believe this file was compressed the best as it is most likely the simpliest of the files as there isn't many different colors in the bitmap and as a result of this would cause there to be very few unique codewords that would need to be added to the codebook to compress this file. The files that compressed the worst `frosty.jpg` and `Lego-big.gif` were quite unique as they were the only two files to expand or not compress at all depending on the algorithm. These two files expanded in all the algorithms except for in the Unix algorithm, which i stated above as to why I believe they didn't, as for why I believe these files expanded I believe it could be in part due to a one of if not two or more reasons with the first being, like I stated above about why the Unix algorithm doesn't cause it to expand, because there is no form of check in the code to see if the resulting file is bigger than the original file. The other reason I think could cause these two files to expand when they are compressed is because of the file format, while I don't know how gifs or jpgs are formatted I'd assume that something with how these files are formatted in that when going to encode the data for each of the pixels in the file the LZW compression algorithm causes it to be more data then there was in the original file and as such causes the file to be bigger.
## Compression Tables
Below are tables containing information regarding each of the compression algorithms and how much it compressed each of the provided test files for the Project.

|File|Original Size|Compressed Size with Original Provided Algorithm|Compression Ratio|
|----------------|-------------|-------------------------------------|-----------------|
|all.tar|2,960KB|1,804KB|740:451|
|assig2.doc|85KB|73KB|85:73|
|bmps.tar|1080KB|904KB|135:113|
|code.txt|71KB|31KB|71:31|
|code2.txt|57KB|24KB|19:8|
|edit.exe|231KB|245KB|33:35|
|frosty.jpg|124KB|174KB|62:87|
|gone_fishing.bmp|17KB|10KB|17:10|
|large.txt|1,193KB|592KB|1193:592|
|Lego-big.gif|92KB|126KB|46:63|
|medium.txt|25KB|13KB|25:13|
|texts.tar|1,350KB|989KB|1350:989|
|wacky.bmp|901KB|5KB|901:5|
|winnt256.bmp|154KB|156KB|77:78|

|File|Original Size|Compressed Size with Resetting |Compression Ratio|
|----------------|-------------|-------------------------------------|-----------------|
|all.tar|2,960KB|1,151KB|2960:1151|
|assig2.doc|85KB|40KB|17:8|
|bmps.tar|1080KB|80KB|27:2|
|code.txt|71KB|24KB|71:24|
|code2.txt|57KB|21KB|19:7|
|edit.exe|231KB|149KB|231:149|
|frosty.jpg|124KB|168KB|31:42|
|gone_fishing.bmp|17KB|9KB|17:9|
|large.txt|1,193KB|516KB|1193:516|
|Lego-big.gif|92KB|120KB|23:30|
|medium.txt|25KB|13KB|25:13|
|texts.tar|1,350KB|577KB|1350:577|
|wacky.bmp|901KB|4KB|901:4|
|winnt256.bmp|154KB|62KB|77:31|

|File|Original Size|Compressed Size without Resetting|Compression Ratio|
|----------------|-------------|-------------------------------------|-----------------|
|all.tar|2,960KB|1,751KB|2960:1751|
|assig2.doc|85KB|40KB|17:8|
|bmps.tar|1080KB|80KB|27:2|
|code.txt|71KB|24KB|71:24|
|code2.txt|57KB|21KB|19:7|
|edit.exe|231KB|153KB|77:51|
|frosty.jpg|124KB|160KB|31:40|
|gone_fishing.bmp|17KB|9KB|17:9|
|large.txt|1,193KB|491KB|1193:491|
|Lego-big.gif|92KB|120KB|23:30|
|medium.txt|25KB|13KB|25:13|
|texts.tar|1,350KB|584KB|675:292|
|wacky.bmp|901KB|4KB|901:4|
|winnt256.bmp|154KB|62KB|77:31|

|File|Original Size|Compressed Size with Unix Compression|Compression Ratio|
|----------------|-------------|-------------------------------------|-----------------|
|all.tar|2,960KB|1,152KB|185:72|
|assig2.doc|85KB|40KB|17:8|
|bmps.tar|1080KB|80KB|27:2|
|code.txt|71KB|24KB|71:24|
|code2.txt|57KB|21KB|19:7|
|edit.exe|231KB|148KB|231:148|
|frosty.jpg|124KB|124KB|1:1|
|gone_fishing.bmp|17KB|9KB|17:9|
|large.txt|1,193KB|511KB|1193:511|
|Lego-big.gif|92KB|92KB|1:1|
|medium.txt|25KB|13KB|25:13|
|texts.tar|1,350KB|576KB|75:32|
|wacky.bmp|901KB|4KB|901:4|
|winnt256.bmp|154KB|62KB|77:31|


